<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>NBA All-Star Predictions</title>
  <meta name="description" content="NBA All-Star Predictions" />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="NBA All-Star Predictions" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="NBA All-Star Predictions" />
  
  
  

<meta name="author" content="Eric Drew" />


<meta name="date" content="2022-12-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">NBA ASG Predictions</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="#nba-all-star-predictions"><i class="fa fa-check"></i><b>1</b> NBA All-Star Predictions</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="#methodologydata-prep"><i class="fa fa-check"></i><b>1.2</b> Methodology/Data Prep</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="#exploratory-data-analysis-eda"><i class="fa fa-check"></i><b>1.3</b> Exploratory Data Analysis (EDA)</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="#modeling"><i class="fa fa-check"></i><b>1.4</b> Modeling</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="#results"><i class="fa fa-check"></i><b>1.5</b> Results</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">NBA All-Star Predictions</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">NBA All-Star Predictions</h1>
<p class="author"><em>Eric Drew</em></p>
<p class="date"><em>2022-12-20</em></p>
</div>
<div id="nba-all-star-predictions" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">1</span> NBA All-Star Predictions<a href="#nba-all-star-predictions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Introduction<a href="#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Objective</strong></p>
<p>Utilize an Extreme Gradient Boosting model, hereafter referred to as “XGBoost”, to predict the NBA All-Star roster for the 2022-23 season.</p>
<p><strong>Background</strong></p>
<p>Each season in February, 24 of the NBA’s top performing players are selected as All-Stars. 12 players represent each of the East and West Conferences with the following breakdown:</p>
<ul>
<li>Four guards (Point Guard, Shooting Guard)</li>
<li>Six frontcourt players (Small Forward, Power Forward, Center)</li>
<li>Two additional players, regardless of position</li>
</ul>
<p>Starting lineups are selected by a combination of fan, current player, and media votes, while the reserve players are chosen by the league’s 30 head coaches. Injured players will be replaced by a player selected by the league’s Commissioner, Adam Silver.</p>
<p><strong>Data</strong></p>
<p>The model will be built off of players’ “per game” statistics from the 2003-04 to 2021-22 seasons, accessed from the public sports database Basketball-Reference. Player statistics from the current season, which is only ~30 games in at the time of writing, will be used as our test dataset. I aim to update my predictions in January and again in February just before the rosters are announced, allowing me to assess my models predictive power in real-time. While the model will not change during this period, new data will be available as players continue to complete more games in the coming months.</p>
</div>
<div id="methodologydata-prep" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Methodology/Data Prep<a href="#methodologydata-prep" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>I will utilize a combination of common and advanced Python libraries to complete the project. The following code is living and may be adapted as the project continues.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> zscore</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder, LabelEncoder</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> make_column_transformer</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, KFold, RepeatedStratifiedKFold, train_test_split, cross_val_score, RandomizedSearchCV</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc, roc_auc_score, RocCurveDisplay, plot_confusion_matrix</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.calibration <span class="im">import</span> calibration_curve</span></code></pre></div>
<p>Now we will read in our 19 seasons of player per game statistics to build our training set on.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>s03 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season03-04.csv&#39;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>s04 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season04-05.csv&#39;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>s05 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season05-06.csv&#39;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>s06 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season06-07.csv&#39;</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>s07 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season07-08.csv&#39;</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>s08 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season08-09.csv&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>s09 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season09-10.csv&#39;</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>s10 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season10-11.csv&#39;</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>s11 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season11-12.csv&#39;</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>s12 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season12-13.csv&#39;</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>s13 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season13-14.csv&#39;</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>s14 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season14-15.csv&#39;</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>s15 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season15-16.csv&#39;</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>s16 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season16-17.csv&#39;</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>s17 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season17-18.csv&#39;</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>s18 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season18-19.csv&#39;</span>)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>s19 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season19-20.csv&#39;</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>s20 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season20-21.csv&#39;</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>s21 <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season21-22.csv&#39;</span>)</span></code></pre></div>
<p>A handful of things that needed to be done to the datasets before I could concatenate all 19 seasons into the cumulative training set.</p>
<p><strong>Scaling by Season</strong></p>
<p>The NBA is an incredibly dynamic league and has changed dramatically over the last decades. For example, the average points scored by a team per game has fluctuated a good bit just in the time horizon we are concerned with in this project, with a high of 112.1 PPG in 2020-21 and a low of 93.4 PPG in 2003-04, a difference of nearly 20 points per game. Because of changes like these, it is difficult to compare raw statistics between players across seasons, especially those over a decade apart. For example, a player scoring 20 PPG in 2003 was likely more impactful than a 20 PPG scorer in 2020, and in the context of our project’s scope may be the difference between an All-Star or not. The question of whether a player is an All-Star is likely not as simple as “how many points per game do they score?” but “how does their scoring average compare to the rest of the league?”</p>
<p>To combat this challenge, I scaled each season’s data individually using Z-scores, allowing us to measure how strong a player’s stat line was compared to the league <em>that season</em>. We then will be able to compare players across time by how much they stood out across a distribution, regardless of the season they played in.</p>
<p>Examples of these calculations are shown below.</p>
<pre><code>df[&#39;PTS&#39;] = zscore(df[&#39;PTS&#39;])
df[&#39;Age&#39;] = zscore(df[&#39;Age&#39;])`
df[&#39;PF&#39;] = zscore(df[&#39;PF&#39;])</code></pre>
<p><strong>Observation Exclusion</strong></p>
<p>In exploring the data, one challenge I discovered in the data was that for players who were traded or played for multiple seasons had more than one observation. These players had observations representing their stats while playing for each team during a season, as well as a cumulative season stat line, which was represented by their team being “TOT” for total. For the purposes of my model, I dropped the individual team stat line observations, and kept only the total season stats for a player.</p>
<pre><code>df = df.sort_values([&#39;Player&#39;,&#39;G&#39;], ascending = [True, False])
df = df.drop_duplicates(subset=[&#39;Player&#39;], keep=&#39;first&#39;)</code></pre>
<p>Another concern was the data being too imbalanced for a model to find meaningful signal in. Most NBA seasons see over 450 individual players log minutes in at least one game. Left as this, the league would contain roughly ~5% All-Stars, crossing into rare-event territory. Seeing as players who rarely see the court are not going to be in contention for making the All-Star roster as is, I decided to subset our data to retain only players who played <em>at least</em> 15 minutes per 48 minute game. This was in an attempt to reduce the noise caused by an overwhelming amount of players who only enter games for a handful of minutes per game at best, whose statistics would intuitively not bring any predictive power in separating All-Stars versus those who are not. Another point of note
is that across NBA history, the All-Star who played the least minutes per game was Dirk Nowitzki in 2018-19. Since
no other NBA player in history has made an All-Star game without playing at least 15 minutes per game, I deemed
this a useful cutoff for players that would be deemed up for contention to be an All-Star.</p>
<pre><code>df = df[df[&#39;MP&#39;] &gt;= 15]</code></pre>
<p>Lastly, some miscellaneous manipulations needed to be made to the datasets, such dropping irrelevant variables such as an ID variable, and removing random special characters found in some observations.</p>
<pre><code>df = df.drop([&#39;Rk&#39;,&#39;Player-additional&#39;,&#39;Tm&#39;], axis=1)
df[&#39;Player&#39;] = df[&#39;Player&#39;].str.replace(&#39;\W&#39;, &#39;&#39;, regex=True)</code></pre>
<p>To more efficiently apply these manipulations across all 19 datasets, I created a function to run them each through, as opposed to writing these commands for each one. The code for this, which is a culmination of the above commands, is shown below.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#create list of dataframes to be used in loops(TRAIN ONLY)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>dfList <span class="op">=</span> [s03,s04,s05,s06,s07,s08,s09,s10,s11,s12,s13,s14,s15,s16,s17,s18,s19,s20,s21]</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#cleaning function removing TOTs, keep to players &gt;=15MPG, scale continuous variables, remove special characters on name</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trainPrep(df):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> df.drop([<span class="st">&#39;Rk&#39;</span>,<span class="st">&#39;Player-additional&#39;</span>,<span class="st">&#39;Tm&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> df.sort_values([<span class="st">&#39;Player&#39;</span>,<span class="st">&#39;G&#39;</span>], ascending <span class="op">=</span> [<span class="va">True</span>, <span class="va">False</span>])</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> df.drop_duplicates(subset<span class="op">=</span>[<span class="st">&#39;Player&#39;</span>], keep<span class="op">=</span><span class="st">&#39;first&#39;</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> df[df[<span class="st">&#39;MP&#39;</span>] <span class="op">&gt;=</span> <span class="dv">15</span>]</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;Age&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;Age&#39;</span>])</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;G&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;G&#39;</span>])</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;GS&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;GS&#39;</span>])</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;MP&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;MP&#39;</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;FG&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FG&#39;</span>])</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;FGA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FGA&#39;</span>])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;FG%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FG%&#39;</span>])</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;3P&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;3P&#39;</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;3PA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;3PA&#39;</span>])</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;2P&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;2P&#39;</span>])</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;2PA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;2PA&#39;</span>])</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;2P%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;2P%&#39;</span>])</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;eFG%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;eFG%&#39;</span>])</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;FT&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FT&#39;</span>])</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;FTA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FTA&#39;</span>])</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;FT%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FT%&#39;</span>])</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;ORB&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;ORB&#39;</span>])</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;DRB&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;DRB&#39;</span>])</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;TRB&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;TRB&#39;</span>])</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;AST&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;AST&#39;</span>])</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;STL&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;STL&#39;</span>])</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;BLK&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;BLK&#39;</span>])</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;TOV&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;TOV&#39;</span>])</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;PF&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;PF&#39;</span>])</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;PTS&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;PTS&#39;</span>])</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>  df[<span class="st">&#39;Player&#39;</span>]<span class="op">=</span>df[<span class="st">&#39;Player&#39;</span>].<span class="bu">str</span>.replace(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">W&quot;</span>,<span class="st">&#39;&#39;</span>,regex<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> df</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Run training sets through cleaning function</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>s03,s04,s05,s06,s07,s08,s09,s10,s11,s12,s13,s14,s15,s16,s17,s18,s19,s20,s21 <span class="op">=</span>[trainPrep(df) <span class="cf">for</span> df <span class="kw">in</span> dfList]</span></code></pre></div>
<p><strong>Target Variable Creation</strong></p>
<p>Next, I created lists of each of the All-Star rosters from the past 19 seasons. I then assigned a new variable, ‘AllStar’, to each player in each dataset. Players on the All-Star roster for that season received a value of 1, while players who were not All-Stars received a 0. An example of this is shown below. The object “ASG03” represents the list of All-Stars from the 2003-04 season.</p>
<pre><code>s03[&#39;AllStar&#39;] = np.where(np.isin(s03[&#39;Player&#39;],ASG03), 1, 0)</code></pre>
<p>Now that each of the individual datasets have been properly manipulated with the target variable added, we can concatenate them together to form our training dataset.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#re-establish dfList with updated DFs</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>dfList <span class="op">=</span> [s03,s04,s05,s06,s07,s08,s09,s10,s11,s12,s13,s14,s15,s16,s17,s18,s19,s20,s21]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Concatenate the training seasons</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.concat(dfList)</span></code></pre></div>
<p>Quickly we will check the distribution of All-Stars(1) in our overall training set.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;AllStar&#39;</span>].value_counts()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#roughly 8% of the data is AllStar, may not need to oversample</span></span></code></pre></div>
<pre><code>## 0    5563
## 1     494
## Name: AllStar, dtype: int64</code></pre>
<p>Next, I applied a label encoder to ensure the target variable is an appropriate binary object for modeling
purposes.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Change numeric to binary target</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;AllStar&#39;</span>] <span class="op">=</span> label_encoder.fit_transform(train[<span class="st">&#39;AllStar&#39;</span>])</span></code></pre></div>
<p>Since we have added the appropriate All-Star labels to all players in our training set, we can now
drop the player name variable, as it does not provide any predictive power.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Drop player col</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> train.drop([<span class="st">&#39;Player&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p>Next, I noticed the dataset took many values for the position variable, as some players are listed as
playing two positions (ex: “PG-SG”). To clean this up, I combined levels into the guard and frontcourt
labels we will use for our predicted roster selection.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Check which values of position are taken across training set for aggregation</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>train.Pos.value_counts()</span></code></pre></div>
<pre><code>## SG          1335
## PG          1207
## PF          1158
## SF          1134
## C           1085
## SF-SG         23
## PG-SG         21
## SG-PG         18
## PF-SF         16
## C-PF          14
## SG-SF         14
## PF-C          13
## SF-PF         13
## SG-PF          4
## PG-SF          1
## SG-PG-SF       1
## Name: Pos, dtype: int64</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Combine Guard/Front-Court positions</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>train[<span class="st">&#39;Pos&#39;</span>] <span class="op">=</span> np.where(((train[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;PG&#39;</span>)) <span class="op">|</span> (train[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;SG&#39;</span>)) <span class="op">|</span> (train[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;PG-SG&#39;</span>)) <span class="op">|</span>(train[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;SG-PG&#39;</span>)) <span class="op">|</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                         (train[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;SG-PF&#39;</span>))<span class="op">|</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    (train[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;SG-PG-SF&#39;</span>))),<span class="st">&#39;Guard&#39;</span>,<span class="st">&#39;Frontcourt&#39;</span>)</span></code></pre></div>
<p>Tree based models like an XGBoost generally do not do well handling categorical variables. For this
reason, I used One-Hot Encoding on our categorical position variable.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>transformer <span class="op">=</span> make_column_transformer(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    (OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>), [<span class="st">&#39;Pos&#39;</span>]),</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    remainder <span class="op">=</span> <span class="st">&#39;passthrough&#39;</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>transformed <span class="op">=</span> transformer.fit_transform(train)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.DataFrame(transformed, columns<span class="op">=</span>transformer.get_feature_names_out())</span></code></pre></div>
<p><strong>Test Dataset</strong></p>
<p>Now that our training dataset is finalized, we can create our test dataset with the current season’s
data. As always in a modeling project, we must manipulate the test set in the same manner we did our training
set.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Test set read in</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(<span class="st">&#39;C:/Users/ericd/OneDrive - North Carolina State University/Desktop/NBA-AllStar-Predictions/Data/season22-23.csv&#39;</span>)</span></code></pre></div>
<p>Similar to with the training set, I created a new function to apply all manipulations to the test set at once, including the scaling, position variable cleaning, and One-Hot Encoding.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Test set cleaning function</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> testPrep(df):</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.sort_values([<span class="st">&#39;Player&#39;</span>,<span class="st">&#39;G&#39;</span>], ascending <span class="op">=</span> [<span class="va">True</span>, <span class="va">False</span>])</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.drop_duplicates(subset<span class="op">=</span>[<span class="st">&#39;Player&#39;</span>], keep<span class="op">=</span><span class="st">&#39;first&#39;</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df[df[<span class="st">&#39;MP&#39;</span>] <span class="op">&gt;=</span> <span class="dv">15</span>]</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df.drop([<span class="st">&#39;Rk&#39;</span>,<span class="st">&#39;Tm&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;Age&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;Age&#39;</span>])</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;G&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;G&#39;</span>])</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;GS&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;GS&#39;</span>])</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;MP&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;MP&#39;</span>])</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;FG&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FG&#39;</span>])</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;FGA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FGA&#39;</span>])</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;FG%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FG%&#39;</span>])</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;3P&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;3P&#39;</span>])</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;3PA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;3PA&#39;</span>])</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;2P&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;2P&#39;</span>])</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;2PA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;2PA&#39;</span>])</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;2P%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;2P%&#39;</span>])</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;eFG%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;eFG%&#39;</span>])</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;FT&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FT&#39;</span>])</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;FTA&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FTA&#39;</span>])</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;FT%&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;FT%&#39;</span>])</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;ORB&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;ORB&#39;</span>])</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;DRB&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;DRB&#39;</span>])</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;TRB&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;TRB&#39;</span>])</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;AST&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;AST&#39;</span>])</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;STL&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;STL&#39;</span>])</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;BLK&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;BLK&#39;</span>])</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;TOV&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;TOV&#39;</span>])</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;PF&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;PF&#39;</span>])</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;PTS&#39;</span>] <span class="op">=</span> zscore(df[<span class="st">&#39;PTS&#39;</span>])</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">&#39;Pos&#39;</span>] <span class="op">=</span> np.where(((df[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;PG&#39;</span>)) <span class="op">|</span> (df[<span class="st">&#39;Pos&#39;</span>].eq(<span class="st">&#39;SG&#39;</span>))),<span class="st">&#39;Guard&#39;</span>,<span class="st">&#39;Frontcourt&#39;</span>)</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    <span class="co">#one hot encoding for test</span></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>    transformer <span class="op">=</span> make_column_transformer(</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>    (OneHotEncoder(sparse<span class="op">=</span><span class="va">False</span>), [<span class="st">&#39;Pos&#39;</span>]),</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>    remainder <span class="op">=</span> <span class="st">&#39;passthrough&#39;</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    transformed <span class="op">=</span> transformer.fit_transform(df)</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame(transformed, columns<span class="op">=</span>transformer.get_feature_names_out())</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span></code></pre></div>
<p>I then ran the test set through the function defined above.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Send test set through cleaning function</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> testPrep(test)</span></code></pre></div>
</div>
<div id="exploratory-data-analysis-eda" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Exploratory Data Analysis (EDA)<a href="#exploratory-data-analysis-eda" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now it was time to look at a few of our variables at a closer level. Intuitively we can expect that All-Stars
generally have better stats than the average player; it is also important to remember that minutes played per game
likely plays a large role in statistics as well. Let’s take a look at some of these variables visually.</p>
<p>First, let’s see how minutes and points correlate.
<img src="bookdownproj_files/figure-html/unnamed-chunk-21-1.png" width="672" />
As we can see, there is a pretty clear positive, linear relationship between the variables. However, one thing
to note is how after the scaled minutes per game value exceeds 1, the points per game values seem to increase at a
slightly steeper rate. This could be, as previously mentioned, the fact that the best players play the most
minutes and are also the ones scoring the most points.</p>
<p>Next we will take a look at how points per game looks across our All-Stars versus non All-Stars.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>sns.boxplot(x <span class="op">=</span> train[<span class="st">&#39;remainder__AllStar&#39;</span>],</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>            y <span class="op">=</span> train[<span class="st">&#39;remainder__PTS&#39;</span>])</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Boxplot of Points/Game by All-Star Status&#39;</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;All-Star Status&#39;</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Points/Game (Scaled)&#39;</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-22-3.png" width="672" />
Unsurprisingly, All-Stars generally score at a much more standout level than their peers. In fact,
the median scoring value for an All-Star is about 2 standard deviations from league standard, which encompasses
roughly the top 5% of scorers in the league. It is also noted that there were outliers for All-Stars that scored
below the league standard.</p>
<p>Next, let’s look at how field goal % compares across All-Star status.
<img src="bookdownproj_files/figure-html/unnamed-chunk-23-5.png" width="672" /></p>
<p>Interesting to see how the medians across both groups are roughly at 0, or league standard. However, the most
notable observation here is how the spread of the non-All-Stars is vastly larger than the All-Stars, stretching
down as far as nearly 8 standard deviations below the mean.</p>
<p>Lastly, let’s look at a correlation matrix across all of our variables.
<img src="bookdownproj_files/figure-html/unnamed-chunk-24-7.png" width="672" />
While a bit difficult to interpret easily, there are a few interesting takeaways. First, Field Goal % seems to
have a strong, negative correlation with other shooting statistics. This may represent players who
take very few shots, but make them at a high clip, leaving them with high shooting percentages with low attempts.
We also see that the age variable seems to have no notable correlations with any other variable. I would have
expected to see stats, especially percentages, drop as a player ages, but evidently, this is not as glaring of
a trend as I thought.</p>
</div>
<div id="modeling" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Modeling<a href="#modeling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that our training/test datasets are prepared, and we have explored our data, it is time to set up our modeling
procedure.</p>
<p><strong>Data Split</strong></p>
<p>First, we will create our X and Y objects. The X object will contain only our predictor variables, while the Y
object will be a list containing the values of the target variable.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Create X and Y object for data split function</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> train.drop([<span class="st">&#39;remainder__AllStar&#39;</span>],axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> train[<span class="st">&#39;remainder__AllStar&#39;</span>].values</span></code></pre></div>
<p>Since we do not have the All-Star values for our test set at the time of this writing, I chose to split our training
set into a training and validation set. The true training set will be used to build the model, with the
validation set being used for model assessment. The code to split these datasets is shown below.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">#data split</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>X_train, X_valid, Y_train, Y_valid <span class="op">=</span> train_test_split(X, Y, test_size <span class="op">=</span> <span class="fl">.2</span>, stratify<span class="op">=</span>Y, random_state<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
<p><strong>Model Fitting</strong></p>
<p>Next, I will establish our XGBoost regressor object.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Establish XGB regressor</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.XGBRegressor(objective<span class="op">=</span><span class="st">&quot;binary:logistic&quot;</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<p>Cross-validation is a key technique to apply in model building to help avoid over-fitting on the training set. For
our model, I will use 10-fold cross-validation, repeated 3 times.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set CV params</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>cv <span class="op">=</span> RepeatedStratifiedKFold(n_splits <span class="op">=</span> <span class="dv">10</span>, n_repeats <span class="op">=</span> <span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<p>I decided to utilize a small grid search across tuning hyperparameters for the model. This allows us to try out
many combinations of key aspects of an XGBoost, such as the depth of the trees and the number of trees in the forest.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Establish tuning parameters</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;max_depth&quot;</span>:[<span class="dv">10</span>,<span class="dv">15</span>,<span class="dv">20</span>],</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;n_estimators&quot;</span>:[<span class="dv">200</span>,<span class="dv">400</span>,<span class="dv">600</span>],</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;min_samples_split&quot;</span>:[<span class="dv">5</span>,<span class="dv">10</span>]</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Next, I set our grid search object with the tuning parameters and cross-validation specifics. I chose the area under
the ROC curve (AUROC) to serve as our cross-validation metric.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set gridsearch object. Use ROC as our CV measure</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GridSearchCV(xgb_model, params, cv<span class="op">=</span>cv, scoring<span class="op">=</span><span class="st">&#39;roc_auc&#39;</span>)</span></code></pre></div>
<p>Now it is time to run the model.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Fit model</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>tick <span class="op">=</span> time.time()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>clf.fit(X_train,Y_train)</span></code></pre></div>
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=0),
             estimator=XGBRegressor(base_score=None, booster=None,
                                    callbacks=None, colsample_bylevel=None,
                                    colsample_bynode=None,
                                    colsample_bytree=None,
                                    early_stopping_rounds=None,
                                    enable_categorical=False, eval_metric=None,
                                    feature_types=None, gamma=None, gpu_id=None,
                                    grow_policy=None, importan...
                                    max_cat_threshold=None,
                                    max_cat_to_onehot=None, max_delta_step=None,
                                    max_depth=None, max_leaves=None,
                                    min_child_weight=None, missing=nan,
                                    monotone_constraints=None, n_estimators=100,
                                    n_jobs=None, num_parallel_tree=None,
                                    objective=&#x27;binary:logistic&#x27;, predictor=None, ...),
             param_grid={&#x27;max_depth&#x27;: [10, 15, 20],
                         &#x27;min_samples_split&#x27;: [5, 10],
                         &#x27;n_estimators&#x27;: [200, 400, 600]},
             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchCV</label><div class="sk-toggleable__content"><pre>GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=0),
             estimator=XGBRegressor(base_score=None, booster=None,
                                    callbacks=None, colsample_bylevel=None,
                                    colsample_bynode=None,
                                    colsample_bytree=None,
                                    early_stopping_rounds=None,
                                    enable_categorical=False, eval_metric=None,
                                    feature_types=None, gamma=None, gpu_id=None,
                                    grow_policy=None, importan...
                                    max_cat_threshold=None,
                                    max_cat_to_onehot=None, max_delta_step=None,
                                    max_depth=None, max_leaves=None,
                                    min_child_weight=None, missing=nan,
                                    monotone_constraints=None, n_estimators=100,
                                    n_jobs=None, num_parallel_tree=None,
                                    objective=&#x27;binary:logistic&#x27;, predictor=None, ...),
             param_grid={&#x27;max_depth&#x27;: [10, 15, 20],
                         &#x27;min_samples_split&#x27;: [5, 10],
                         &#x27;n_estimators&#x27;: [200, 400, 600]},
             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">estimator: XGBRegressor</label><div class="sk-toggleable__content"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=None, num_parallel_tree=None,
             objective=&#x27;binary:logistic&#x27;, predictor=None, ...)</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">XGBRegressor</label><div class="sk-toggleable__content"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=None, num_parallel_tree=None,
             objective=&#x27;binary:logistic&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>tock <span class="op">=</span> time.time()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Fit complete&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Time Taken: </span><span class="sc">{</span><span class="bu">round</span>((tock<span class="op">-</span>tick)<span class="op">/</span><span class="dv">60</span>,<span class="dv">2</span>)<span class="sc">}</span><span class="ss"> minutes&quot;</span>)</span></code></pre></div>
<p>With the grid search complete, we will take the best outcome and store it as our final model, as well as
look at the selected hyperparameters.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Take best model from grid search</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>final_model <span class="op">=</span> clf.best_estimator_</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#View parameters of the selected model</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>final_model.get_params()</span></code></pre></div>
<pre><code>## {&#39;objective&#39;: &#39;binary:logistic&#39;, &#39;base_score&#39;: 0.5, &#39;booster&#39;: &#39;gbtree&#39;, &#39;callbacks&#39;: None, &#39;colsample_bylevel&#39;: 1, &#39;colsample_bynode&#39;: 1, &#39;colsample_bytree&#39;: 1, &#39;early_stopping_rounds&#39;: None, &#39;enable_categorical&#39;: False, &#39;eval_metric&#39;: None, &#39;feature_types&#39;: None, &#39;gamma&#39;: 0, &#39;gpu_id&#39;: -1, &#39;grow_policy&#39;: &#39;depthwise&#39;, &#39;importance_type&#39;: None, &#39;interaction_constraints&#39;: &#39;&#39;, &#39;learning_rate&#39;: 0.300000012, &#39;max_bin&#39;: 256, &#39;max_cat_threshold&#39;: 64, &#39;max_cat_to_onehot&#39;: 4, &#39;max_delta_step&#39;: 0, &#39;max_depth&#39;: 20, &#39;max_leaves&#39;: 0, &#39;min_child_weight&#39;: 1, &#39;missing&#39;: nan, &#39;monotone_constraints&#39;: &#39;()&#39;, &#39;n_estimators&#39;: 200, &#39;n_jobs&#39;: 0, &#39;num_parallel_tree&#39;: 1, &#39;predictor&#39;: &#39;auto&#39;, &#39;random_state&#39;: 0, &#39;reg_alpha&#39;: 0, &#39;reg_lambda&#39;: 1, &#39;sampling_method&#39;: &#39;uniform&#39;, &#39;scale_pos_weight&#39;: 1, &#39;subsample&#39;: 1, &#39;tree_method&#39;: &#39;exact&#39;, &#39;validate_parameters&#39;: 1, &#39;verbosity&#39;: None, &#39;min_samples_split&#39;: 5}</code></pre>
<p><strong>Model Assessment</strong></p>
<p>With our final model set, let’s see how it did on our validation dataset by plotting the area under the ROC curve.</p>
<pre><code>## (0.0, 1.0)</code></pre>
<pre><code>## (0.0, 1.0)</code></pre>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-37-9.png" width="768" /></p>
<p>With an AUROC value of <em>.98</em>, we can feel confident that our model did a solid job distinguishing
our All-Stars from the non All-Stars.</p>
<p><strong>Variable Importance</strong></p>
<p>Let’s now look at which variables had the biggest impact on our model’s predictions. We will limit this
to the top 10 most impactful predictors.</p>
<pre><code>## (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), [Text(0, 0, &#39;remainder__PTS&#39;), Text(0, 1, &#39;remainder__FG&#39;), Text(0, 2, &#39;remainder__MP&#39;), Text(0, 3, &#39;remainder__AST&#39;), Text(0, 4, &#39;remainder__DRB&#39;), Text(0, 5, &#39;remainder__GS&#39;), Text(0, 6, &#39;remainder__TRB&#39;), Text(0, 7, &#39;remainder__Age&#39;), Text(0, 8, &#39;remainder__FGA&#39;), Text(0, 9, &#39;remainder__G&#39;)])</code></pre>
<p>Unsurprisingly, points per game was by far the most important variable to our model’s predictions. Intuitively,
seeing field goals made per game following it in second place makes sense as well, as the variables would be
highly correlated (more made shots = more points).</p>
</div>
<div id="results" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Results<a href="#results" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Predictions</strong></p>
<p>Now we are ready to see what predicted probabilities our model assigns to our current players. We will split
the test set by East and West Conference players, then rank them by All-Star probability.</p>
<p>First, our top Eastern All-Star Candidates:</p>
<pre><code>##                     Player         Pos  All-Star Probability
## 124           Kevin Durant  Frontcourt              0.999696
## 425           Jayson Tatum  Frontcourt              0.999165
## 130            Joel Embiid  Frontcourt              0.998936
## 10   Giannis Antetokounmpo  Frontcourt              0.997491
## 360     Kristaps Porziņģis  Frontcourt              0.989537
## 307       Donovan Mitchell       Guard              0.964376
## 170      Tyrese Haliburton       Guard              0.931938
## 106          DeMar DeRozan  Frontcourt              0.931248
## 61            Jaylen Brown  Frontcourt              0.927927
## 174           James Harden       Guard              0.829841
## 487             Trae Young       Guard              0.777516
## 69            Jimmy Butler  Frontcourt              0.170591
## 45        Bojan Bogdanović  Frontcourt              0.153535
## 371          Julius Randle  Frontcourt              0.058978
## 405          Pascal Siakam  Frontcourt              0.035210</code></pre>
<p>Next, for the Western Conference.</p>
<pre><code>##                       Player         Pos  All-Star Probability
## 114              Luka Dončić       Guard              0.999909
## 100            Anthony Davis  Frontcourt              0.999656
## 98             Stephen Curry       Guard              0.998754
## 151  Shai Gilgeous-Alexander       Guard              0.997617
## 216             LeBron James  Frontcourt              0.992093
## 226             Nikola Jokić  Frontcourt              0.990028
## 314                Ja Morant       Guard              0.988147
## 48              Devin Booker       Guard              0.963103
## 265           Damian Lillard       Guard              0.882354
## 394         Domantas Sabonis  Frontcourt              0.772665
## 480          Zion Williamson  Frontcourt              0.692026
## 280          Lauri Markkanen  Frontcourt              0.085584
## 465        Russell Westbrook       Guard              0.039078
## 158             Jerami Grant  Frontcourt              0.031536
## 140             De&#39;Aaron Fox       Guard              0.024825</code></pre>
<p>Now, there are a few initial reactions I have to these results. First, the model has done a great
job at being near certain that the league’s most elite players will be All-Stars. Stephen Curry,
Kevin Durant, and Jayson Tatum are all players who find themselves consistently in the conversation
for Most Valuable Player. They are near-locks to be an All-Star every season. Our model identified
top performers such as them, giving them over a 99% probability of making the All-Star team.</p>
<p>What I find most interesting is how quickly the predicted probabilities drop off after you get past
the elite. For example, in our Eastern Conference table, after Zion Williamson (69.2%% probability),
the next highest drops to Lauri Markkanen at just over 8%. In fact, even the 15th highest
probability in the conference, De’Aaron Fox, has only a 2.4% chance of making it. This tells that
our model will generally assign incredibly high or low probabilities to players. I believe that
through these results, we can segment the league into three rough categories:</p>
<ul>
<li><p>Elite All-Star (Top 15 player)</p></li>
<li><p>Fringe All-Star (16-35th best player)</p></li>
<li><p>Rest of league (36th and lower)</p></li>
</ul>
<p>Top players will be clear standouts to make the cut with little to no debate. These should be
obvious even to the casual fan. However, there are likely 20 or so players with above-average stats
but do not stand out as elite. Players of this type are much more common than the elite, however
only have roughly 5 All-Star spots per conference to fill. Because of this, the individual
probability of this type of player making the All-Star game is likely much lower, explaining the
significant drop-off in probabilities in both conferences. Based on the model output, I would
suspect that any player with above a 1% chance of making the All-Star game is likely a top 50 player
across the league, despite how low this value sounds.</p>
<p><strong>Limitations</strong></p>
<p>While generally pleased with the model results, I would like to address a few areas of limitation.
First, the selection criteria. While this model makes predictions from an objective, statistical standpoint, this is not how it is selected in practice. As mentioned in the background section, All-Stars are selected via a mix of the fan, player, media, and coach votes. Subjectivity, especially for super-fans who spend hours submitting numerous votes for their favorite players, can cause some skew in the results. This may also apply to the players and coaches who hold some implicit bias towards their teammates or friends in the league. Since voting procedures have changed over the years, it would be incredibly challenging to feature engineer this into the dataset for improved predictions.</p>
<p>Another concern is the rare occasion in which an NBA legend retires. Generally, as shown over the years, well-loved and celebrated players are selected for the All-Star game, despite their stats not showing them as a standout. An example of this that was mentioned earlier is Dirk Nowitzki being selected as an All-Star in 2018-19. While only playing 15 minutes per game and averaging less than 8 points per game, Dirk still made the roster. Similar to Kobe Bryant ( 17 points per game on 35% shooting) and Dwyane Wade (15 points per game) in 2016 and 2018, respectively, this act of respect to an outgoing legend does serve as an outlier. While infrequent, the model takes all instances of an All-Star selection into account without this consideration without this added context.</p>
<p><strong>Next Steps</strong></p>
<p>I thoroughly enjoyed working on this project and am greatly pleased with the results of the models’ predictive power. With that being said, the fun part has yet to come. At the time of this writing (Dec. 2022), I plan to update the model’s predictions two times between now and February, just before the All-Star rosters are officially announced. I hope to store the predictions from each time point to track and compare which players are the biggest risers and fallers as the season continues and more data rolls in. Come February, I hope to present a final All-Star roster prediction, in which I will assess the accuracy of following the announcements.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ericrdrew/NBA-AllStar-Predictions/edit/master/index.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ericrdrew/NBA-AllStar-Predictions/blob/master/index.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
